{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmnist\n",
    "\n",
    "net = pretrainedmnist.mnist(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: \n",
    "At the end, ANOTHER version, trained myself, with pytorch (experiment on runge kutta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.Resize((28,28)),\n",
    "#     transforms.Grayscale(),\n",
    "     transforms.ToTensor()])\n",
    "#,\n",
    " #    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imsave\n",
    "import io\n",
    "import sqlite3\n",
    "def make_connection(p):\n",
    "    return sqlite3.connect(p)\n",
    "def preload_all_queries(conn, more=''):\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT id_a,student,* FROM capture_zone WHERE type=4 '''+more+''' ORDER BY student,id_a,id_b ASC''')\n",
    "    res = {}\n",
    "    for r in c.fetchall():\n",
    "        k = r[1]\n",
    "        if not (k in res):\n",
    "            res[k] = []\n",
    "        r = r[:-1] + (imread(io.BytesIO(r[-1])),)\n",
    "        #import pytesseract\n",
    "        #print(pytesseract.image_to_string(imread(io.BytesIO(r[-1])), config='--psm 10'))\n",
    "        # ^ doesn't seem to work too well on this data\n",
    "        #import base64\n",
    "        #r = r[:-1] + (base64.b64encode(r[-1]).decode('ascii'),)\n",
    "        #im = imread(io.BytesIO(r[-1]))\n",
    "        res[k].append(r)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = preload_all_queries(make_connection('test3/capture.sqlite'), more=' AND student='+str(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#im = info[42][2][13]\n",
    "#im = np.transpose(info[42][2][13], [0,1,2])\n",
    "#im = np.array([np.array(info[42][i][13]) for i in range(10)])\n",
    "im = np.array([transform(info[42][i][13]).numpy()[0,:,:] for i in range(20)]) \n",
    "#print(im.shape)\n",
    "#im = transform(im)\n",
    "#plt.imshow(im[0,:,:])\n",
    "#print(im.min(), im.max(), im.shape)\n",
    "#im = (im - np.mean(im)) / np.std(im)\n",
    "\n",
    "#transform(im.shape)\n",
    "with torch.no_grad():\n",
    "    print(im.size)\n",
    "    pred = net(torch.from_numpy(im))\n",
    "    print(pred.shape)\n",
    "    print(np.argmax(pred, axis=1), pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((28,28)),\n",
    "        #transforms.Resize((50,50)),\n",
    "        #transforms.CenterCrop((28,28)),\n",
    "        #transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = info[42][81][13]\n",
    "im0 = im\n",
    "print(im.shape)\n",
    "im = np.transpose(transform(im0).numpy(), [1,2,0])\n",
    "print(im.shape)\n",
    "R = im[:,:,0]\n",
    "G = im[:,:,1]\n",
    "B = im[:,:,2]\n",
    "#im = np.sum(im, axis=2) / 3 #, np.array(im[:,:,1:2])# - np.sum(im, axis=2, keepdims=True))\n",
    "#im[((B*2-G-R)>.05)] = np.max(im)\n",
    "#im[((R*2-G-B)>.05)] = np.max(im)\n",
    "\n",
    "im = np.sum(im, axis=2) / 3 #, np.array(im[:,:,1:2])# - np.sum(im, axis=2, keepdims=True))\n",
    "im = (im - np.min(im)) / (np.max(im) - np.min(im))\n",
    "\n",
    "im[((B*2-G-R)>.05)] = np.max(im)\n",
    "im[((R*2-G-B)>.05)] = np.max(im)\n",
    "im = 1 - im\n",
    "\n",
    "print(im.shape)\n",
    "#plt.imshow(im)\n",
    "plt.imshow(im, cmap='gray')\n",
    "#im = transform(im[:,:,0]).numpy()\n",
    "print(np.min(im), np.max(im))\n",
    "im2 = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = torch.load('model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    #transforms.Resize((28,28)),\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.CenterCrop((28,28)),\n",
    "    #transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "print(im0.shape, im2.shape)\n",
    "im = np.array((im2[...,np.newaxis]*np.ones((1,1,3)))*255, dtype=np.uint8)\n",
    "print(im.shape, np.min(im), np.max(im))\n",
    "batch = transform2(im)\n",
    "batch = batch[np.newaxis, 1:2, ::, ::]\n",
    "print(batch.shape, torch.min(batch), torch.max(batch))\n",
    "\n",
    "\n",
    "#print(\"batch\", batch.shape, batch.numpy().shape)\n",
    "plt.imshow(batch.numpy()[0,0,:,:])\n",
    "\n",
    "print(batch.min(), batch.max())\n",
    "##batch = batch.transpose(0,1)\n",
    "#print(batch.shape)\n",
    "#batch = batch.numpy()#.sum(keepdims = True)\n",
    "#batch = torch.from_numpy(batch[np.newaxis])\n",
    "#print(batch.shape)\n",
    "with torch.no_grad():\n",
    "    pred = net(batch)\n",
    "print(np.argmax(pred), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
